# Chatbot Full-Stack

Una aplicaciÃ³n de chatbot inteligente construida con Next.js (frontend) y Node.js con Serverless Framework (backend). El chatbot puede responder preguntas sobre envÃ­os, devoluciones, precios y estado de pedidos utilizando reglas predefinidas y opcionalmente OpenAI.

## ğŸ—ï¸ Arquitectura

```
chatbot-fullstack/
â”œâ”€â”€ frontend/                 # AplicaciÃ³n Next.js (Puerto 3000)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx     # PÃ¡gina principal del chat
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ health/
â”‚   â”‚   â”‚       â””â”€â”€ route.ts # Health check del frontend
â”‚   â”‚   â””â”€â”€ layout.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ChatInterface.tsx # Componente principal del chat
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ chat.ts          # Tipos TypeScript
â”‚   â””â”€â”€ .env.local           # Variables de entorno del frontend
â”œâ”€â”€ backend/                 # LÃ³gica serverless (Puerto 3001)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.ts      # Handler principal del chat
â”‚   â”‚   â”‚   â””â”€â”€ health.ts    # Handler de health check
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ chatService.ts
â”‚   â”‚   â”‚   â””â”€â”€ llmService.ts
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ logger.ts
â”‚   â”œâ”€â”€ serverless.yml       # ConfiguraciÃ³n serverless
â”‚   â””â”€â”€ .env                 # Variables de entorno del backend
â””â”€â”€ README.md
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- **Node.js** versiÃ³n 18 o superior
- **npm** o **yarn**
- **Clave de OpenAI** (opcional, para respuestas con IA)

### 1. Clonar el repositorio

```bash
git clone <url-del-repositorio>
cd chatbot-fullstack
```

### 2. Configurar el Backend

```bash
cd backend
npm install
```

#### Instalar Serverless Framework globalmente:
```bash
npm install -g serverless
```

#### Crear archivo `.env` en la carpeta `backend`:
```bash
# backend/.env
OPENAI_API_KEY=tu_clave_de_openai_aqui
NODE_ENV=development
```

> **Nota**: La clave de OpenAI es opcional. Sin ella, el chatbot funcionarÃ¡ solo con reglas predefinidas.

### 3. Configurar el Frontend

```bash
cd frontend
npm install
```

#### Crear archivo `.env.local` en la carpeta `frontend`:
```bash
# frontend/.env.local
NEXT_PUBLIC_API_URL=http://localhost:3001
```

## ğŸ¯ Ejecutar la AplicaciÃ³n

### 1. Iniciar el Backend (Puerto 3001)

```bash
cd backend
serverless offline
```

DeberÃ­as ver:
```
Starting Offline at stage dev (us-east-1)
Offline [http for lambda] listening on http://localhost:3001

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   POST    | http://localhost:3001/dev/api/chat                              â”‚
â”‚   OPTIONS | http://localhost:3001/dev/api/chat                              â”‚
â”‚   GET     | http://localhost:3001/dev/api/health                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Server ready: http://localhost:3001 ğŸš€
```

### 2. Iniciar el Frontend (Puerto 3000)

En una nueva terminal:
```bash
cd frontend
npm run dev
```

### 3. Acceder a la AplicaciÃ³n

Abre tu navegador en: **http://localhost:3000/chat**

## ğŸ“‹ Funcionalidades

### Respuestas AutomÃ¡ticas por Reglas

El chatbot responde automÃ¡ticamente a estas preguntas (insensible a mayÃºsculas/acentos):

- **EnvÃ­o**: "Â¿CÃ³mo funciona el envÃ­o?" â†’ _"Los pedidos tardan 2â€“3 dÃ­as hÃ¡biles a ciudades principales."_
- **DevoluciÃ³n**: "Â¿Puedo devolver un producto?" â†’ _"Tienes 30 dÃ­as para devolver; aplica polÃ­tica de estado y factura."_
- **Precio**: "Â¿CuÃ¡nto cuesta este producto?" â†’ _"Los precios se actualizan a diario; verifica la ficha del producto."_
- **Estado de Pedido**: "Â¿CuÃ¡l es el estado de mi pedido?" â†’ _Devuelve informaciÃ³n de tracking mock_

### Respuestas con IA (OpenAI)

Para preguntas que no coinciden con las reglas, el sistema puede usar OpenAI para generar respuestas mÃ¡s inteligentes.

### ID de Cliente

Para consultas de estado de pedido, puedes ingresar un ID de cliente en el campo opcional para obtener informaciÃ³n de tracking simulada.

## ğŸ”§ Endpoints de la API

### Backend (Puerto 3001)

- **POST** `/dev/api/chat` - Procesar preguntas del chatbot
- **GET** `/dev/api/health` - Health check del backend

### Frontend (Puerto 3000)

- **GET** `/api/health` - Health check del frontend
- **GET** `/chat` - Interfaz principal del chat

## ğŸ“ Estructura de Datos

### PeticiÃ³n al Chat
```json
{
  "question": "Â¿CÃ³mo funciona el envÃ­o?",
  "customerId": "12345"
}
```

### Respuesta del Chat
```json
{
  "answer": "Los pedidos tardan 2â€“3 dÃ­as hÃ¡biles a ciudades principales.",
  "source": "rules",
  "timestamp": "2025-08-28T19:30:00.000Z",
  "tracking": {
    "status": "EN_CAMINO",
    "eta": "48h",
    "carrier": "MockExpress"
  }
}
```

## ğŸ§ª Pruebas

### Probar el Backend directamente

```bash
# Health check
curl http://localhost:3001/dev/api/health

# Enviar pregunta
curl -X POST http://localhost:3001/dev/api/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "Â¿CÃ³mo funciona el envÃ­o?"}'
```

### Preguntas de Ejemplo

1. **"Â¿CÃ³mo funciona el envÃ­o?"** - Respuesta por reglas
2. **"Â¿Puedo devolver un producto?"** - Respuesta por reglas  
3. **"Â¿CuÃ¡nto cuesta?"** - Respuesta por reglas
4. **"estado de mi pedido"** (con Customer ID) - InformaciÃ³n de tracking
5. **"Â¿QuÃ© productos recomiendan?"** - Respuesta por IA (si OpenAI estÃ¡ configurado)

## ğŸš¨ SoluciÃ³n de Problemas

### Error "Method not allowed"
- Verificar que el backend estÃ© corriendo en puerto 3001
- Confirmar que la variable `NEXT_PUBLIC_API_URL` estÃ© configurada correctamente

### Error "Variables resolution errored"
- Verificar que el archivo `.env` exista en la carpeta `backend`
- Confirmar que `OPENAI_API_KEY` estÃ© definida (o comentar esa lÃ­nea en `serverless.yml`)

### Puerto ya en uso
```bash
custom:
  serverless-offline:
    httpPort: 3001 
```

### Frontend no se conecta al backend
- Verificar que `NEXT_PUBLIC_API_URL` en `.env.local` apunte al puerto correcto
- Confirmar que ambos servidores estÃ©n corriendo

## Desarrollo

### Estructura del Proyecto

- **Frontend**: Next.js 13+ con App Router, TypeScript, Tailwind CSS
- **Backend**: Node.js, TypeScript, Serverless Framework, OpenAI API
- **Base de datos**: No requiere (usa datos mock)

### Scripts Disponibles

**Backend:**
```bash
npm run dev          # serverless offline
npm run build        # Compilar TypeScript
npm run deploy       # Deploy a AWS (si estÃ¡ configurado)
```

**Frontend:**
```bash
npm run dev          # Next.js desarrollo
npm run build        # Build de producciÃ³n
npm run start        # Servidor de producciÃ³n
npm run lint         # ESLint
```

## TecnologÃ­as

### Frontend
- **Next.js 13+** - Framework React
- **TypeScript** - Tipado estÃ¡tico
- **Tailwind CSS** - Estilos
- **Lucide React** - Iconos

### Backend
- **Node.js** - Runtime
- **TypeScript** - Tipado estÃ¡tico
- **Serverless Framework** - Despliegue serverless
- **OpenAI API** - Inteligencia artificial (opcional)

## Seguridad

- Variables de entorno para configuraciÃ³n sensible
- ValidaciÃ³n de entrada en el backend
- CORS configurado correctamente
- Rate limiting y timeouts configurados
- Logging estructurado para auditorÃ­a

## Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

---

Copyright Â© Todos los derechos reservados